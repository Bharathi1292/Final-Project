{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d38c5403-8647-4736-8c30-af82b5916093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Row_ID: integer (nullable = true)\n |-- Order_ID: string (nullable = true)\n |-- Order_Date: date (nullable = true)\n |-- Ship_Date: date (nullable = true)\n |-- Ship_Mode: string (nullable = true)\n |-- Customer_ID: string (nullable = true)\n |-- Customer_Name: string (nullable = true)\n |-- Segment: string (nullable = true)\n |-- Country: string (nullable = true)\n |-- City: string (nullable = true)\n |-- State: string (nullable = true)\n |-- Postal_Code: integer (nullable = true)\n |-- Region: string (nullable = true)\n |-- Product_ID: string (nullable = true)\n |-- Category: string (nullable = true)\n |-- Sub-Category: string (nullable = true)\n |-- Product_Name: string (nullable = true)\n |-- Sales: float (nullable = true)\n |-- Order_Month: integer (nullable = true)\n |-- Order_Year: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "df = spark.read.format(\"delta\").load(\"/FileStore/delta/superstore_transformed\")\n",
    "\n",
    "# Display schema to understand the data structure\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e190ebb2-baad-409e-8bde-3f1bd4911e59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+\n|       Category|      Total_Sales|\n+---------------+-----------------+\n|Office Supplies|690139.7993411422|\n|      Furniture|719791.4541658163|\n|     Technology|827201.9049543142|\n+---------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "####Aggregating Total Sales by Product Category####\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# Aggregating total sales by category\n",
    "total_sales_by_category = df.groupBy(\"Category\").agg(\n",
    "    sum(\"Sales\").alias(\"Total_Sales\")\n",
    ")\n",
    "\n",
    "# Show the aggregated result\n",
    "total_sales_by_category.show()\n",
    "\n",
    "# Storing aggregated data (e.g., total sales by category) in a Delta table\n",
    "total_sales_by_category.write.format(\"delta\").mode(\"overwrite\").save(\"/FileStore/delta/aggregated_sales_by_category\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "230bd773-a4bb-4164-942a-301f9e65e073",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n| Region|       Total_Sales|\n+-------+------------------+\n|  South|386413.13934862614|\n|Central|489321.39007872343|\n|   East| 663043.8557248116|\n|   West| 698354.7733091116|\n+-------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "######Aggregating Total Sales by Region#######\n",
    "\n",
    "# Aggregating total sales by region\n",
    "total_sales_by_region = df.groupBy(\"Region\").agg(\n",
    "    sum(\"Sales\").alias(\"Total_Sales\")\n",
    ")\n",
    "\n",
    "# Show the aggregated result\n",
    "total_sales_by_region.show()\n",
    "\n",
    "# Storing aggregated data (e.g., total sales by region) in a Delta table\n",
    "total_sales_by_region.write.format(\"delta\").mode(\"overwrite\").save(\"/FileStore/delta/total_sales_by_region\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfb24787-882a-4c83-aefe-95af7a433494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n|    Segment|     Average_Sales|\n+-----------+------------------+\n|   Consumer| 229.2131426626457|\n|Home Office|248.55639851867377|\n|  Corporate| 237.9783451178598|\n+-----------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "######Average Sales by Customer Segment#####\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Aggregating average sales by segment\n",
    "average_sales_by_segment = df.groupBy(\"Segment\").agg(\n",
    "    avg(\"Sales\").alias(\"Average_Sales\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "average_sales_by_segment.show()\n",
    "\n",
    "\n",
    "# Storing aggregated data (e.g., average sales by segment) in a Delta table\n",
    "average_sales_by_segment.write.format(\"delta\").mode(\"overwrite\").save(\"/FileStore/delta/average_sales_by_segment\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c46f62a-354e-4aa1-ae4f-f01a5faabd0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n|Customer_ID|Order_Count|\n+-----------+-----------+\n|   VW-21775|         18|\n|   RR-19315|          4|\n|   PB-19210|          2|\n|   MY-17380|         13|\n|   MS-17530|          7|\n|   EM-13960|          6|\n|   AH-10690|         23|\n|   SW-20275|          7|\n|   KH-16630|         17|\n|   BD-11500|         10|\n|   JF-15490|         14|\n|   PH-18790|          2|\n|   JF-15415|         13|\n|   PW-19240|         12|\n|   IM-15070|         21|\n|   KM-16225|         19|\n|   NW-18400|         22|\n|   KF-16285|         18|\n|   JH-15985|         14|\n|   OT-18730|         10|\n+-----------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "########Count of Orders per Customer#####\n",
    "from pyspark.sql.functions import count\n",
    "# Aggregating count of orders by customer\n",
    "orders_per_customer = df.groupBy(\"Customer_ID\").agg(\n",
    "    count(\"Order_ID\").alias(\"Order_Count\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "orders_per_customer.show()\n",
    "\n",
    "\n",
    "# Storing aggregated data (e.g., orders_per_customer) in a Delta table\n",
    "orders_per_customer.write.format(\"delta\").mode(\"overwrite\").save(\"/FileStore/delta/orders_per_customer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "547f239c-bb3e-4a99-b32c-01d57fbd327e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+------------------+\n|       Category|      Total_Sales|     Average_Sales|\n+---------------+-----------------+------------------+\n|Office Supplies|690139.7993411422| 121.7177776615771|\n|      Furniture|719791.4541658163|354.05383874363815|\n|     Technology|827201.9049543142|458.28360385280564|\n+---------------+-----------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "##########Multiple Aggregations (e.g., Total Sales, Average Sales)##########\n",
    "\n",
    "\n",
    "# Aggregating both total and average sales by category\n",
    "sales_by_category = df.groupBy(\"Category\").agg(\n",
    "    sum(\"Sales\").alias(\"Total_Sales\"),\n",
    "    avg(\"Sales\").alias(\"Average_Sales\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "sales_by_category.show()\n",
    "\n",
    "# Storing aggregated data (e.g., sales_by_category) in a Delta table\n",
    "sales_by_category.write.format(\"delta\").mode(\"overwrite\").save(\"/FileStore/delta/sales_by_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b865c51-12d4-4ed4-a920-b93d4a40c19c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+\n|       Category|      Total_Sales|\n+---------------+-----------------+\n|Office Supplies|690139.7993411422|\n|      Furniture|719791.4541658163|\n|     Technology|827201.9049543142|\n+---------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "###############Grouping and Aggregating Using SQL###########\n",
    "\n",
    "# Register the DataFrame as a temporary view for SQL queries\n",
    "df.createOrReplaceTempView(\"superstore_view\")\n",
    "\n",
    "# Run SQL query to aggregate total sales by category\n",
    "Group_aggregate_result = spark.sql(\"\"\"\n",
    "    SELECT Category, SUM(Sales) AS Total_Sales\n",
    "    FROM superstore_view\n",
    "    GROUP BY Category\n",
    "\"\"\")\n",
    "\n",
    "# Show the result\n",
    "Group_aggregate_result.show()\n",
    "\n",
    "Group_aggregate_result.write.format(\"delta\").mode(\"overwrite\").save(\"/FileStore/delta/Group_aggregate_result\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be36eb8c-3641-4ec4-a940-5c091c998825",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Aggregation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
