{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9799d014-d8d1-40ba-8ff8-698df239e5ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Row_ID: integer (nullable = true)\n |-- Order_ID: string (nullable = true)\n |-- Order_Date: date (nullable = true)\n |-- Ship_Date: date (nullable = true)\n |-- Ship_Mode: string (nullable = true)\n |-- Customer_ID: string (nullable = true)\n |-- Customer_Name: string (nullable = true)\n |-- Segment: string (nullable = true)\n |-- Country: string (nullable = true)\n |-- City: string (nullable = true)\n |-- State: string (nullable = true)\n |-- Postal_Code: integer (nullable = true)\n |-- Region: string (nullable = true)\n |-- Product_ID: string (nullable = true)\n |-- Category: string (nullable = true)\n |-- Sub-Category: string (nullable = true)\n |-- Product_Name: string (nullable = true)\n |-- Sales: string (nullable = true)\n\n+------+--------------+----------+----------+--------------+-----------+---------------+---------+-------------+---------------+----------+-----------+------+---------------+---------------+------------+--------------------+--------+\n|Row_ID|      Order_ID|Order_Date| Ship_Date|     Ship_Mode|Customer_ID|  Customer_Name|  Segment|      Country|           City|     State|Postal_Code|Region|     Product_ID|       Category|Sub-Category|        Product_Name|   Sales|\n+------+--------------+----------+----------+--------------+-----------+---------------+---------+-------------+---------------+----------+-----------+------+---------------+---------------+------------+--------------------+--------+\n|     1|CA-2017-152156|2017-11-08|2017-11-11|  Second Class|   CG-12520|    Claire Gute| Consumer|United States|      Henderson|  Kentucky|      42420| South|FUR-BO-10001798|      Furniture|   Bookcases|Bush Somerset Col...|  261.96|\n|     2|CA-2017-152156|2017-11-08|2017-11-11|  Second Class|   CG-12520|    Claire Gute| Consumer|United States|      Henderson|  Kentucky|      42420| South|FUR-CH-10000454|      Furniture|      Chairs|Hon Deluxe Fabric...|  731.94|\n|     3|CA-2017-138688|2017-06-12|2017-06-16|  Second Class|   DV-13045|Darrin Van Huff|Corporate|United States|    Los Angeles|California|      90036|  West|OFF-LA-10000240|Office Supplies|      Labels|Self-Adhesive Add...|   14.62|\n|     4|US-2016-108966|2016-10-11|2016-10-18|Standard Class|   SO-20335| Sean O'Donnell| Consumer|United States|Fort Lauderdale|   Florida|      33311| South|FUR-TA-10000577|      Furniture|      Tables|Bretford CR4500 S...|957.5775|\n|     5|US-2016-108966|2016-10-11|2016-10-18|Standard Class|   SO-20335| Sean O'Donnell| Consumer|United States|Fort Lauderdale|   Florida|      33311| South|OFF-ST-10000760|Office Supplies|     Storage|Eldon Fold 'N Rol...|  22.368|\n+------+--------------+----------+----------+--------------+-----------+---------------+---------+-------------+---------------+----------+-----------+------+---------------+---------------+------------+--------------------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session (if you haven't already)\n",
    "spark = SparkSession.builder.appName(\"SuperstoreSales\").getOrCreate()\n",
    "\n",
    "# Load superstore sales data from a CSV file\n",
    "superstore_sales_data_url = \"/FileStore/tables/train-7.csv\"  # Ensure this is the correct path\n",
    "df = spark.read.format(\"csv\") \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .load(superstore_sales_data_url)\n",
    "\n",
    "# Clean column names: Replace spaces with underscores and remove special characters\n",
    "def clean_column_names(df):\n",
    "    for col_name in df.columns:\n",
    "        # Replace spaces with underscores and remove any special characters\n",
    "        new_col_name = col_name.replace(\" \", \"_\") \\\n",
    "                                .replace(\"(\", \"\") \\\n",
    "                                .replace(\")\", \"\") \\\n",
    "                                .replace(\",\", \"\") \\\n",
    "                                .replace(\";\", \"\") \\\n",
    "                                .replace(\"\\n\", \"\") \\\n",
    "                                .replace(\"\\t\", \"\") \\\n",
    "                                .replace(\"=\", \"\")\n",
    "        df = df.withColumnRenamed(col_name, new_col_name)\n",
    "    return df\n",
    "\n",
    "# Clean the column names in the DataFrame\n",
    "df = clean_column_names(df)\n",
    "\n",
    "# Show the cleaned column names and the first few rows of the dataset\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "\n",
    "# Save the raw cleaned data into a Delta table\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/FileStore/delta/superstore_raw\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ce7bff2-42bf-44e4-9059-2bee131e2309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataLoading",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
